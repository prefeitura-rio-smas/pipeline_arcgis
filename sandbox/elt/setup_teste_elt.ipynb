{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d65dbb28",
   "metadata": {},
   "source": [
    "# Conex√£o com o BigQuery\n",
    "\n",
    "- Objetivo: conectar ao bigquery, testar os comando de cria√ß√£o de tabela e overwrite e lapidar para a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cd392e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importa o SDK e configura o projeto (opcional)\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74113c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_path = Path('/root/pipelines/arcgis/abordagem') / '.env'\n",
    "load_dotenv(dotenv_path=env_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9055960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Cria o cliente\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "718da9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úîÔ∏è Datasets encontrados no projeto:\n",
      "  ‚Ä¢ arcgis_raw\n",
      "  ‚Ä¢ dashboard_cadunico_subex\n",
      "  ‚Ä¢ dashboard_cfc_subex\n",
      "  ‚Ä¢ protecao_social_cadunico\n",
      "  ‚Ä¢ teste_abordagem\n"
     ]
    }
   ],
   "source": [
    "# 3. Lista os datasets no projeto\n",
    "datasets = list(client.list_datasets())\n",
    "if datasets:\n",
    "    print(\"‚úîÔ∏è Datasets encontrados no projeto:\")\n",
    "    for ds in datasets:\n",
    "        print(f\"  ‚Ä¢ {ds.dataset_id}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nenhum dataset encontrado. Verifique PROJECT_ID e credenciais.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11807d8",
   "metadata": {},
   "source": [
    "# Conex√£o com o Arcgis\n",
    "\n",
    "- Objetivo: conectar a feature, analisar os dados e lapidar para a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3840705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.gis import GIS\n",
    "from arcgis.features import FeatureLayer\n",
    "import pandas as pd\n",
    "\n",
    "ARCIS_PORTAL_URL_SIURB = os.getenv(\"ARCIS_PORTAL_URL_SIURB\")\n",
    "ARCIS_USER_SIURB = os.getenv(\"ARCIS_USER_SIURB\")\n",
    "ARCIS_PWD_SIURB = os.getenv(\"ARCIS_PWD_SIURB\")\n",
    "\n",
    "ARCIS_PORTAL_URL_AGOL = os.getenv(\"ARCIS_PORTAL_URL_AGOL\")\n",
    "ARCIS_USER_AGOL = os.getenv(\"ARCIS_USER_AGOL\")\n",
    "ARCIS_PWD_AGOL = os.getenv(\"ARCIS_PWD_AGOL\")\n",
    "\n",
    "ARCIS_ABORDAGEM_FEATURE_SIURB = os.getenv(\"ARCIS_ABORDAGEM_FEATURE_SIURB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0db5dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîê Logando na conta siurb...\n",
      "‚úÖ Logado como: SMAS_ed01\n"
     ]
    }
   ],
   "source": [
    "# Exemplo para notebooks: input controlado\n",
    "opcao = input(\"Deseja logar em qual conta? Digite 'siurb' ou 'agol': \").strip().lower()\n",
    "\n",
    "if opcao == \"siurb\":\n",
    "    print(f\"üîê Logando na conta {opcao}...\")\n",
    "    gis = GIS(ARCIS_PORTAL_URL_SIURB, ARCIS_USER_SIURB, ARCIS_PWD_SIURB)\n",
    "elif opcao == \"agol\":\n",
    "    print(f\"üîê Logando na conta {opcao}...\")\n",
    "    gis = GIS(ARCIS_PORTAL_URL_AGOL, ARCIS_USER_AGOL, ARCIS_PWD_AGOL)\n",
    "else:\n",
    "    raise ValueError(\"Op√ß√£o inv√°lida. Use 'siurb' ou 'agol'.\")\n",
    "\n",
    "# Confirma√ß√£o da conta logada\n",
    "print(f\"‚úÖ Logado como: {gis.users.me.username}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9d5859",
   "metadata": {},
   "source": [
    "***Listagem das camadas usadas at√© o momento***\n",
    "\n",
    "*Abordagem SIURB ID = 6832ff4ca54c4608b169682ae3a5b088*\n",
    "\n",
    "*Abordagem AGOL ID = 1ef5fb0ea56c42849d338bb30d796b0f*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1bab144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conta: siurb\n",
      "T√≠tulo: ABORDAGEM SOCIAL - CPSR (2023.2)\n",
      "Layers : ['Ficha de Abordagem Social - SMAS', 'repeat_abordagem']\n",
      "Tables : []\n"
     ]
    }
   ],
   "source": [
    "# Input do ID da camada\n",
    "item_id = ARCIS_ABORDAGEM_FEATURE_SIURB\n",
    "item = gis.content.get(item_id)\n",
    "\n",
    "# Confirma√ß√£o do item recuperado\n",
    "if item:\n",
    "    print(\"Conta:\", opcao)\n",
    "    print(\"T√≠tulo:\", item.title)\n",
    "    print(\"Layers :\", [lyr.properties.name   for lyr in item.layers])\n",
    "    print(\"Tables :\", [tbl.properties.name   for tbl in item.tables])\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nenhum item encontrado com esse ID.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f37d18",
   "metadata": {},
   "source": [
    "# 2.1 Ficha de Abordagem Social ‚Äì SMAS\n",
    "\n",
    "- Layer index 0: `\"Ficha de Abordagem Social - SMAS\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1408971a",
   "metadata": {},
   "source": [
    "***Conectando para pegar os dados no arcgis***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd68e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# j√° temos `item = gis.content.get(...)`\n",
    "layer_smas = item.layers[0]  \n",
    "print(\"Conta:\", opcao)\n",
    "print(\"URL da layer:\", layer_smas.url)\n",
    "\n",
    "# consulta sem geometria, pegando s√≥ as colunas\n",
    "fl = layer_smas.query(\n",
    "    where=\"1=1\",\n",
    "    out_fields=\"*\",\n",
    "    return_geometry=False,\n",
    "    max_records=5\n",
    ")\n",
    "\n",
    "# converte para pandas\n",
    "df_smas = fl.sdf  \n",
    "print(\"Linhas √ó Colunas:\", df_smas.shape)\n",
    "display(df_smas.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83310674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista todos os campos definidos no servi√ßo\n",
    "fields = [fld[\"name\"] for fld in layer_smas.properties.fields]\n",
    "print(\"Total de campos no servi√ßo:\", len(fields))\n",
    "print(fields)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4332e6e0",
   "metadata": {},
   "source": [
    "**Pontos de inspe√ß√£o**  \n",
    "- N√∫mero de colunas (`df_smas.shape[1]`)  \n",
    "- Tipos de cada coluna (`df_smas.dtypes`)  \n",
    "- Valores nulos (`df_smas.isna().sum()`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98b7cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detalhes r√°pidos\n",
    "print(df_smas.dtypes)\n",
    "print(\"\\nValores ausentes por coluna:\")\n",
    "print(df_smas.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7119b378",
   "metadata": {},
   "source": [
    "## Processo de ELT\n",
    "\n",
    "**Movimento dos dados para o Bigquery**\n",
    "\n",
    "- Objetivo: Levar os dados para o Bigquery para serem tratados por l√°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f23918",
   "metadata": {},
   "source": [
    "***Mini processo de tratamento, transformando tudo em string e incluindo o timestamp.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d09c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "df_smas[\"timestamp\"] = datetime.now()\n",
    "df_smas = df_smas.astype(\"string\")\n",
    "\n",
    "\n",
    "display(df_smas.head())\n",
    "print(df_smas.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b9af2e",
   "metadata": {},
   "source": [
    "***Subida dos dados para o Bucket***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c114d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "# gera string tipo '20250521_104500'\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Define o nome do arquivo e o path no bucket\n",
    "bucket_name = \"rj-smas-dev\"\n",
    "object_path = f\"raw/arcgis/{opcao}/abordagem/ficha/ficha_{timestamp}.csv\"\n",
    "\n",
    "local_csv = \"/tmp/ficha.csv\"\n",
    "\n",
    "# Salva o dataframe localmente como CSV\n",
    "df_smas.to_csv(local_csv, index=False)\n",
    "\n",
    "# Sobe pro bucket\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blob = bucket.blob(object_path)\n",
    "blob.upload_from_filename(local_csv)\n",
    "\n",
    "print(f\"‚úîÔ∏è CSV enviado ao bucket: gs://{bucket_name}/{object_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fa47f6",
   "metadata": {},
   "source": [
    "# 2.2 repeat_abordagem\n",
    "\n",
    "- Layer index 1: `\"repeat_abordagem\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7864e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# j√° temos `item_x = gis.content.get(...)`\n",
    "layer_smas = item.layers[1]  \n",
    "print(\"Conta:\", opcao)\n",
    "print(\"URL da layer:\", layer_smas.url)\n",
    "\n",
    "# consulta sem geometria, pegando s√≥ as colunas\n",
    "fl = layer_smas.query(\n",
    "    where=\"1=1\",\n",
    "    out_fields=\"*\",\n",
    "    return_geometry=False,\n",
    ")\n",
    "\n",
    "# converte para pandas\n",
    "df_smas = fl.sdf  \n",
    "print(\"Linhas √ó Colunas:\", df_smas.shape)\n",
    "display(df_smas.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1d144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista todos os campos definidos no servi√ßo\n",
    "fields = [fld[\"name\"] for fld in layer_smas.properties.fields]\n",
    "print(\"Total de campos no servi√ßo:\", len(fields))\n",
    "print(fields)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d6b92b",
   "metadata": {},
   "source": [
    "**Pontos de inspe√ß√£o**  \n",
    "- N√∫mero de colunas (`df_smas.shape[1]`)  \n",
    "- Tipos de cada coluna (`df_smas.dtypes`)  \n",
    "- Valores nulos (`df_smas.isna().sum()`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e55caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detalhes r√°pidos\n",
    "print(df_smas.dtypes)\n",
    "print(\"\\nValores ausentes por coluna:\")\n",
    "print(df_smas.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e811c762",
   "metadata": {},
   "source": [
    "## Processo de EL\n",
    "\n",
    "**Movimento dos dados para o Bigquery**\n",
    "\n",
    "- Objetivo: Levar os dados para o Bigquery para serem tratados por l√°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c78090",
   "metadata": {},
   "source": [
    "### Mini processo de tratamento, transformando tudo em string e incluindo o timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229f3dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "df_smas[\"timestamp\"] = datetime.now()\n",
    "df_smas = df_smas.astype(\"string\")\n",
    "\n",
    "\n",
    "display(df_smas.head())\n",
    "print(df_smas.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ec550c",
   "metadata": {},
   "source": [
    "### Subida dos dados para o Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddfea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "# gera string tipo '20250521_104500'\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Define o nome do arquivo e o path no bucket\n",
    "bucket_name = \"rj-smas-dev\"\n",
    "object_path = f\"raw/arcgis/{opcao}/abordagem/repeat/repeat_{timestamp}.csv\"\n",
    "\n",
    "local_csv = \"/tmp/repeat.csv\"\n",
    "\n",
    "# Salva o dataframe localmente como CSV\n",
    "df_smas.to_csv(local_csv, index=False)\n",
    "\n",
    "# Sobe pro bucket\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blob = bucket.blob(object_path)\n",
    "blob.upload_from_filename(local_csv)\n",
    "\n",
    "print(f\"‚úîÔ∏è CSV enviado ao bucket: gs://{bucket_name}/{object_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db77ccf3",
   "metadata": {},
   "source": [
    "## Processo de T\n",
    "\n",
    "**Tratando os dados do bucket e criando as camadas Bronze**\n",
    "\n",
    "- Objetivo: Criar as Tabelas Externas no BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24115e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api_core.exceptions import NotFound\n",
    "from google.cloud import bigquery, storage\n",
    "import csv\n",
    "\n",
    "PROJECT_ID  = \"rj-smas-dev\"\n",
    "DATASET_ID  = \"arcgis_raw\"\n",
    "BUCKET_NAME = \"rj-smas-dev\"\n",
    "\n",
    "fontes  = [\"siurb\"]\n",
    "tipos   = [\"ficha\", \"repeat\"]\n",
    "\n",
    "bq  = bigquery.Client(project=PROJECT_ID)\n",
    "gcs = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "dataset_ref = f\"{PROJECT_ID}.{DATASET_ID}\"\n",
    "\n",
    "def header_cols(prefix: str):\n",
    "    \"\"\"\n",
    "    Abre o 1¬∫ CSV do prefixo e devolve a lista de colunas.\n",
    "    Evita placeholder de 'pasta' (nome terminando em '/').\n",
    "    \"\"\"\n",
    "    blobs = (b for b in gcs.list_blobs(BUCKET_NAME, prefix=prefix)\n",
    "             if not b.name.endswith(\"/\"))\n",
    "    blob  = next(blobs)                              # pega o primeiro arquivo real\n",
    "    # l√™ s√≥ a primeira linha\n",
    "    with blob.open(\"r\") as f:\n",
    "        header_line = f.readline().strip(\"\\n\")\n",
    "    return next(csv.reader([header_line]))\n",
    "\n",
    "for fonte in fontes:\n",
    "    for tipo in tipos:\n",
    "        table_id = f\"{fonte}_abordagem_{tipo}_raw\"\n",
    "        full_id  = f\"{dataset_ref}.{table_id}\"\n",
    "        uri_glob = f\"gs://{BUCKET_NAME}/raw/arcgis/{fonte}/abordagem/{tipo}/*.csv\"\n",
    "        prefix   = f\"raw/arcgis/{fonte}/abordagem/{tipo}/\"\n",
    "\n",
    "        # --- schema: tudo STRING -------------------\n",
    "        cols   = header_cols(prefix)\n",
    "        schema = [bigquery.SchemaField(col, \"STRING\") for col in cols]\n",
    "\n",
    "        cfg = bigquery.ExternalConfig(\"CSV\")\n",
    "        cfg.source_uris               = [uri_glob]\n",
    "        cfg.autodetect                = False           # vamos indicar o schema manual\n",
    "        cfg.schema                    = schema          # tudo STRING\n",
    "        cfg.options.skip_leading_rows = 1\n",
    "        cfg.options.quote_character   = '\"'             # padr√£o ‚îÄ volta a ser v√°lido\n",
    "        cfg.options.allow_jagged_rows = True            # linhas mais curtas = NULL\n",
    "        cfg.options.allow_quoted_newlines = True        # \\n dentro de \"campo\"\n",
    "        cfg.max_bad_records = 10                      # pula at√© 1000 linhas quebradas\n",
    "\n",
    "\n",
    "        tbl = bigquery.Table(full_id)\n",
    "        tbl.external_data_configuration = cfg\n",
    "        bq.create_table(tbl, exists_ok=True)\n",
    "\n",
    "        print(f\"‚úÖ  {full_id} ‚Üí EXTERNAL (all STRING)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-abordagem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
